{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# InvestigatorAI: Comprehensive RAGAS Evaluation Framework\n",
        "\n",
        "## üéØ Objective\n",
        "This notebook implements comprehensive evaluation of our InvestigatorAI fraud investigation system using RAGAS with both RAG and Agent evaluation metrics:\n",
        "\n",
        "### üìä RAG Evaluation Metrics:\n",
        "- **Faithfulness**: Response grounding in retrieved contexts\n",
        "- **Answer Relevancy**: Response relevance to questions  \n",
        "- **Context Precision**: Relevance of retrieved contexts\n",
        "- **Context Recall**: Completeness of retrieved information\n",
        "\n",
        "### ü§ñ Agent Evaluation Metrics:\n",
        "- **Tool Call Accuracy**: Correct tool usage and parameters\n",
        "- **Agent Goal Accuracy**: Achievement of user's stated goals\n",
        "- **Topic Adherence**: Staying on-topic for fraud investigation\n",
        "\n",
        "### üìà Integration:\n",
        "- **LangSmith**: Capturing evaluation results and conversation traces\n",
        "- **Real Data**: Using official FinCEN/FFIEC/FDIC regulatory documents\n",
        "- **Multi-Agent System**: Evaluating our complete fraud investigation workflow\n",
        "\n",
        "---\n",
        "\n",
        "*Following AI Makerspace evaluation patterns with Task 5 certification requirements*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## üì¶ Dependencies and Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Core dependencies for RAGAS evaluation\n",
        "import os\n",
        "import sys\n",
        "import asyncio\n",
        "from getpass import getpass\n",
        "from datetime import datetime\n",
        "from typing import List, Dict, Any\n",
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "from ragas.llms import LangchainLLMWrapper\n",
        "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
        "from ragas.testset import TestsetGenerator\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "from langchain_community.document_loaders import DirectoryLoader\n",
        "from langchain_community.document_loaders import PyMuPDFLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## üîë API Keys Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîê Setting up API keys for evaluation...\n",
            "‚úÖ API keys configured for evaluation!\n"
          ]
        }
      ],
      "source": [
        "# Configure API keys for evaluation\n",
        "print(\"üîê Setting up API keys for evaluation...\")\n",
        "\n",
        "# OpenAI API Key (required for LLM and embeddings)\n",
        "if not os.getenv(\"OPENAI_API_KEY\"):\n",
        "    os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter your OpenAI API key: \")\n",
        "    \n",
        "# LangSmith API Key (for evaluation tracking)\n",
        "if not os.getenv(\"LANGSMITH_API_KEY\"):\n",
        "    os.environ[\"LANGSMITH_API_KEY\"] = getpass(\"Enter your LangSmith API key: \")\n",
        "\n",
        "# External API keys (if not already set)\n",
        "external_apis = [\n",
        "    \"TAVILY_SEARCH_API_KEY\",\n",
        "    \"ALPHA_VANTAGE_API_KEY\"\n",
        "]\n",
        "\n",
        "for api_key in external_apis:\n",
        "    if not os.getenv(api_key):\n",
        "        response = input(f\"Enter {api_key} (or press Enter to skip): \")\n",
        "        if response.strip():\n",
        "            os.environ[api_key] = response.strip()\n",
        "\n",
        "print(\"‚úÖ API keys configured for evaluation!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## üèóÔ∏è Load InvestigatorAI Components\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîÑ Loading InvestigatorAI components for evaluation...\n",
            "‚úÖ Core InvestigatorAI components loaded!\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "VectorStoreService.__init__() missing 2 required positional arguments: 'embeddings' and 'settings'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m‚úÖ Core InvestigatorAI components loaded!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Initialize services\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m vector_service = \u001b[43mVectorStoreService\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m external_api_service = ExternalAPIService()\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Initialize multi-agent system\u001b[39;00m\n",
            "\u001b[31mTypeError\u001b[39m: VectorStoreService.__init__() missing 2 required positional arguments: 'embeddings' and 'settings'"
          ]
        }
      ],
      "source": [
        "# Import existing InvestigatorAI components\n",
        "print(\"üîÑ Loading InvestigatorAI components for evaluation...\")\n",
        "\n",
        "try:\n",
        "    # Load core components\n",
        "    from api.core.config import Settings, get_settings, initialize_llm_components\n",
        "    from api.services.vector_store import VectorStoreService  \n",
        "    from api.services.external_apis import ExternalAPIService\n",
        "    from api.agents.multi_agent_system import FraudInvestigationSystem\n",
        "    from api.models.schemas import InvestigationRequest\n",
        "    \n",
        "    print(\"‚úÖ Core InvestigatorAI components loaded!\")\n",
        "    \n",
        "    # Initialize settings and LLM components\n",
        "    settings = get_settings()\n",
        "    llm, embeddings = initialize_llm_components(settings)\n",
        "    \n",
        "    print(\"‚úÖ Settings and LLM components initialized!\")\n",
        "    \n",
        "    # Initialize services with required arguments\n",
        "    vector_service = VectorStoreService(embeddings=embeddings, settings=settings)\n",
        "    external_api_service = ExternalAPIService(settings=settings)\n",
        "    \n",
        "    # Initialize multi-agent system\n",
        "    fraud_system = FraudInvestigationSystem(\n",
        "        llm=llm,\n",
        "        external_api_service=external_api_service\n",
        "    )\n",
        "    \n",
        "    print(\"‚úÖ InvestigatorAI system initialized for evaluation!\")\n",
        "    \n",
        "except ImportError as e:\n",
        "    print(f\"‚ö†Ô∏è  Error loading InvestigatorAI components: {e}\")\n",
        "    print(\"üí° Make sure you're running from the project root directory\")\n",
        "except ValueError as e:\n",
        "    print(f\"‚ö†Ô∏è  Configuration error: {e}\")\n",
        "    print(\"üí° Make sure your API keys are set in environment variables\")\n",
        "    \n",
        "    # Fallback initialization for RAGAS evaluation only\n",
        "    print(\"üîÑ Falling back to basic LLM setup for RAGAS evaluation...\")\n",
        "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "    embeddings = OpenAIEmbeddings()\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è  Unexpected error: {e}\")\n",
        "    print(\"üîÑ Using fallback LLM configuration...\")\n",
        "    \n",
        "    # Fallback initialization\n",
        "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "    embeddings = OpenAIEmbeddings()\n",
        "\n",
        "# Wrap with RAGAS wrappers for evaluation\n",
        "generator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4o\", temperature=0))\n",
        "generator_embeddings = LangchainEmbeddingsWrapper(embeddings)\n",
        "\n",
        "print(\"‚úÖ RAGAS LLM and embeddings configured!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## üìÑ Load Regulatory Documents and Generate Synthetic Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load regulatory PDFs and generate synthetic test dataset\n",
        "print(\"üìÑ Loading regulatory documents for evaluation...\")\n",
        "\n",
        "# Load PDF documents from data directory\n",
        "pdf_path = \"data/pdf_downloads/\"\n",
        "loader = DirectoryLoader(pdf_path, glob=\"*.pdf\", loader_cls=PyMuPDFLoader)\n",
        "regulatory_docs = loader.load()\n",
        "\n",
        "print(f\"‚úÖ Loaded {len(regulatory_docs)} regulatory document chunks\")\n",
        "\n",
        "# Generate fraud investigation questions based on the documents\n",
        "fraud_investigation_questions = [\n",
        "    \"What is the SAR filing threshold for wire transfers to high-risk countries?\",\n",
        "    \"What documentation is required for CTR reporting on cash transactions?\",\n",
        "    \"Are there specific red flags for this transaction pattern involving shell companies?\",\n",
        "    \"What are the Enhanced Due Diligence requirements for politically exposed persons?\",\n",
        "    \"Which transactions require immediate law enforcement notification under FinCEN guidance?\",\n",
        "    \"What are the money laundering indicators for wire transfers to the UAE?\",\n",
        "    \"Are there structuring indicators in this series of cash deposits?\",\n",
        "    \"How should suspicious account takeover activities be documented and reported?\",\n",
        "    \"What are the trade-based money laundering red flags in import/export transactions?\",\n",
        "    \"Are there compliance violations in this cryptocurrency exchange pattern?\",\n",
        "    \"What KYC documentation is required for high-risk customer onboarding?\",\n",
        "    \"How should politically exposed person transactions be monitored and reported?\",\n",
        "    \"What are the investigation steps for suspected terrorist financing activities?\",\n",
        "    \"Are there Bank Secrecy Act violations in these transaction patterns?\",\n",
        "    \"What evidence collection procedures should be followed for fraud investigations?\",\n",
        "    \"How should cross-border wire transfer compliance be verified?\",\n",
        "    \"What are the regulatory reporting requirements for this suspicious activity?\",\n",
        "    \"Are there OFAC sanctions screening violations in these transactions?\",\n",
        "    \"What investigation timeline should be followed for this fraud case?\",\n",
        "    \"How should this complex money laundering scheme be analyzed and reported?\"\n",
        "]\n",
        "\n",
        "# Create synthetic dataset structure for RAGAS evaluation\n",
        "print(f\"üéØ Generated {len(fraud_investigation_questions)} fraud investigation questions\")\n",
        "\n",
        "# Display sample questions\n",
        "print(\"\\nüìã Sample fraud investigation questions:\")\n",
        "for i, question in enumerate(fraud_investigation_questions[:5]):\n",
        "    print(f\"  {i+1}. {question}\")\n",
        "\n",
        "print(f\"\\n‚úÖ Dataset ready with {len(fraud_investigation_questions)} questions for evaluation!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "generator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4.1\"))\n",
        "generator_embeddings = LangchainEmbeddingsWrapper(OpenAIEmbeddings())\n",
        "\n",
        "generator = TestsetGenerator(\n",
        "    llm=generator_llm, embedding_model=generator_embeddings)\n",
        "dataset = generator.generate_with_langchain_docs(regulatory_docs[:20], testset_size=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## ü§ñ Generate Responses with InvestigatorAI Multi-Agent System\n",
        "\n",
        "Next sections to implement:\n",
        "- Generate responses using the fraud investigation system\n",
        "- Create RAGAS evaluation samples\n",
        "- Run RAG evaluation (faithfulness, answer relevancy, context precision, context recall)\n",
        "- Run Agent evaluation (tool call accuracy, agent goal accuracy, topic adherence) \n",
        "- Integrate with LangSmith for results tracking\n",
        "- Provide comprehensive performance analysis and recommendations\n",
        "\n",
        "*Implementation following AI Makerspace patterns with complete LangSmith integration*\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "investigator-ai",
      "language": "python",
      "name": "investigator-ai"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
