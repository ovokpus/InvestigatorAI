# Submit Here (Due August 5 by 4:00 PM PT)

> **📂 Navigation**: [🏠 Home](../README.md) | [🤖 Agent Prompts](AGENT_PROMPTS.md) | [🎓 Certification](CERTIFICATION_CHALLENGE.md) | [🎬 Demo Guide](DEMO_GUIDE.md) | [🔄 Merge Instructions](../MERGE.md) | [💻 Frontend Docs](../frontend/README.md) | [📊 Data Docs](../data/README.md) | [🚀 Deploy Docs](../deploy/README.md)

[](https://docs.google.com/forms/d/1dyshpB-Ww4aSuodnA3TyCr9hOssO5ZQhsF4_a8WGZFY/preview)

# **🎬 Live Session Resources, recorded July 29**

<aside>

🖼️ [Slides](https://www.canva.com/design/DAGjaTJe9jA/5TfZJMygwFSS-Auxf6v1BQ/edit?utm_content=DAGjaTJe9jA&utm_campaign=designshare&utm_medium=link2&utm_source=sharebutton) & 🎥 [Recording](https://us02web.zoom.us/rec/share/UZPC5sbV_7JX2KZLMSLo6S7wllZub1sRUTAPL-8Wwt9t3L3SywdaZZT6ISj96eH0.rdAQJl3fW4oYvIlp)(PR%6Cjd=)

📣 [PM Demo ROS](https://www.notion.so/23fcd547af3d80eaab2ac23fe72dfc7f?pvs=21)

🗣️ [Feedback](https://forms.gle/Yg7tGpy4sxnmaehTA)

</aside>

# Overview

Welcome to the middle of the course!  We've made it 5 weeks so far and covered a lot of ground!

It's time to double down on what we're aiming at, and how we plan to build, ship, and share our way to a Demo Day success!

No matter what you're specifically aiming at in your life or career in 2025, adding a fully shipped project to your portfolio *will certainly not hurt* 🏗️🚢🚀!

Let's recall where we've been and what we've covered in the past five weeks

- Introduction, Vibe Check,and RAG
- Production-Grade RAG Apps & Use Cases
- Agents and Multi-Agent Systems
- RAG and Agent Evaluation with Synthetic Data
- Advanced Retrieval and Agentic Reasoning

Remember, *you know enough already to be dangerous*.  Now, **it's time to put your skills to the tes**t.  Do you understand the concepts and code we need to build, ship, and share production LLM applications?  

![image.png](attachment:e41d94f7-00a8-4b69-94fc-5d43e68f6e5a:image.png)

It's time to assign your Certification Challenge, which you must complete to receive a certification 🎖️.

This will also form the basis for what you'll build, ship, and share for Demo Day!

# Introduction

All good stories, like all RAG applications, rely on putting the right stuff in context.

What's the context for your **CERTIFICATION CHALLENGE submission**?

What's the context for your **Demo Day application**?

That's the first thing you need to figure out!

In Cohorts 1-4 of the Bootcamp, we provided the context for students on the Certification.

*They didn't love it, and wished it had more to do with Demo Day.*

In Cohort 5, ****we made students provide the context.

In Cohort 6, *we had students provide the context*, and this worked out very well!

Now, in Cohort 7, this is standard - **you are responsible for deciding what to build and why**. However, **if you cannot come up with a use case, please use the primary cohort use case that** we learned about in [Session 4](https://www.notion.so/Session-4-Production-Grade-RAG-with-LangChain-and-LangSmith-224cd547af3d8092a8a8faa917b5417b?pvs=21) and [Session 6](https://www.notion.so/Session-6-Multi-Agent-Applications-with-LangGraph-22bcd547af3d80f7a2e0cc7a2c6d7d8f?pvs=21).

*That is, we want you to start building, shipping, and sharing your Demo Day project on a deadline, early in the game.*

To do that, we'll need some AI Product Management.

## 😎 AI Product Management

<aside>
🤔

AI product management asks "**What** should I build, ship, and share, and why?"

</aside>

There are three primary questions **you need to answer** *before you can begin* the certification challenge:

1. What **problem** are you trying to solve?  
*Why is this a problem?*
2. What is your proposed **solution**?  
*Why is this the best solution?*
3. Who is the **audience** that has this problem and would use your solution?  
*Do they nod their head up and down when you talk to them about it?*

Problem, Solution, Audience. 

That's really all you need.

From there, you'll need to do some AI Engineering.

## 🧑‍💻 AI Engineering

<aside>
🤔

AI Engineering asks "**How** should I build, ship, and share, and why?"

</aside>

"Should I use RAG or fine-tuning?"

"Should I use Agents or RAG?"

![image.png](attachment:3593d1f0-ffb4-4c67-a5cd-f29109bfd87d:image.png)

![image.png](attachment:82b2b8e4-ed63-4aa3-8862-2d65c5d8efce:image.png)

You will be responsible for helping your current or future companies overcome the illusion of choice.

🙋 "Should I do vibe checking or quantitative evaluation?"

🧑‍💻 "Yes."

🙋 "Should I use Synthetic Data Generation to evaluate or to improve performance?"

🧑‍💻 "Yes." 

🙋 "Should I focus on improving retrieval or generation?"

🧑‍💻 "Yes." 

🙋 "Should I use fine-tuning or embeddings or LLMs to improve performance or decrease costs?"

🧑‍💻 "Yes."

🤚 "How do I make the right tradeoffs?"

🧑‍💻 "mmmmm….yeeeessssssss."

To answer this most important question of tradeoffs, we must of course, go back to AI product management, and align our response with [the three primary questions](https://www.notion.so/Session-11-Certification-Challenge-21dcd547af3d81cbb16dedda007eb69d?pvs=21).

# Task 1: Defining your Problem and Audience

**You are an AI Solutions Engineer**.

**What** problem do you want to solve?  **Who** is it a problem for?

<aside>
📝

Task 1: Articulate the problem and the user of your application

*Hints:* 

- *Create a list of potential questions that your user is likely to ask!*
- *What is the user's job title, and what is the part of their job function that you're trying to automate?*
</aside>

**✅ Deliverables**

1. Write a succinct 1-sentence description of the problem
2. Write 1-2 paragraphs on why this is a problem for your specific user

<aside>
⚠️

**If you cannot come up with a problem worth solving, use the [primary cohort use case](https://www.notion.so/Session-11-Certification-Challenge-21dcd547af3d81cbb16dedda007eb69d?pvs=21) one as a default**.

</aside>

# Task 2: Propose a Solution

Now that you've defined a problem and a user, *there are many possible solutions*.

Choose one, and articulate it.

<aside>
📝

Task 2: Articulate your proposed solution

*Hint:*  

- *Paint a picture of the "better world" that your user will live in.  How will they save time, make money, or produce higher-quality output?*
- *Recall the [LLM Application stack](https://a16z.com/emerging-architectures-for-llm-applications/) we've discussed at length*
</aside>

**✅ Deliverables**

1. Write 1-2 paragraphs on your proposed solution.  How will it look and feel to the user?
2. Describe the tools you plan to use in each part of your stack.  Write one sentence on why you made each tooling choice.
    1. LLM
    2. Embedding Model
    3. Orchestration
    4. Vector Database
    5. Monitoring
    6. Evaluation
    7. User Interface
    8. (Optional) Serving & Inference
3. Where will you use an agent or agents?  What will you use "agentic reasoning" for in your app?

# Task 3: Dealing with the Data

**You are an AI Systems Engineer.**  The AI Solutions Engineer has handed off the plan to you.  Now *you must identify some source data* that you can use for your application.  

Assume that you'll be doing at least RAG (e.g., a PDF) with a general agentic search (e.g., a search API like [Tavily](https://tavily.com/) or [SERP](https://serpapi.com/)).

<aside>
📝

Task 3: Collect data for (at least) RAG and choose (at least) one external API

*Hint:*  

- *Ask other real people (ideally the people you're building for!) what they think.*
- *What are the specific questions that your user is likely to ask of your application?  **Write these down**.*
</aside>

**✅ Deliverables**

1. Describe all of your data sources and external APIs, and describe what you'll use them for.
2. Describe the default chunking strategy that you will use.  Why did you make this decision?
3. [Optional] Will you need specific data for any other part of your application?   If so, explain.

# Task 4: Building a Quick End-to-End Agentic RAG Prototype

<aside>
📝

Task 4: Build an end-to-end Agentic RAG application using a production-grade stack and your choice of commercial off-the-shelf model(s)

</aside>

**✅ Deliverables**

1. Build an end-to-end prototype and deploy it to a *local* endpoint

# Task 5: Creating a Golden Test Data Set

**You are an AI Evaluation & Performance Engineer.**  The AI Systems Engineer who built the initial RAG system has asked for your help and expertise in creating a "Golden Data Set" for evaluation.

<aside>
📝

Task 5: Generate a synthetic test data set to baseline an initial evaluation with RAGAS

</aside>

**✅ Deliverables**

1. Assess your pipeline using the RAGAS framework including key metrics faithfulness, response relevance, context precision, and context recall.  Provide a table of your output results.
2. What conclusions can you draw about the performance and effectiveness of your pipeline with this information?

# Task 6: The Benefits of Advanced Retrieval

**You are an AI Systems Engineer.**  The AI Evaluation and Performance Engineer has asked for your help in making stepwise improvements to the application. They heard that "as goes retrieval, so goes generation" and have asked for your expertise.

<aside>
📝

Task 6: Install an advanced retriever of your choosing in our Agentic RAG application. 

</aside>

**✅ Deliverables**

1. Describe the retrieval techniques that you plan to try and to assess in your application.  Write one sentence on why you believe each technique will be useful for your use case.
2. Test a host of advanced retrieval techniques on your application.

# Task 7: Assessing Performance

**You are the AI Evaluation & Performance Engineer**.  It's time to assess all options for this product.

<aside>
📝

Task 7: Assess the performance of the naive agentic RAG application versus the applications with advanced retrieval tooling

</aside>

**✅ Deliverables**

1. How does the performance compare to your original RAG application?  Test the fine-tuned embedding model using the RAGAS frameworks to quantify any improvements.  Provide results in a table.
2. Articulate the changes that you expect to make to your app in the second half of the course. How will you improve your application?

# Your Final Submission

Please include the following in your final submission:

1. A public (or otherwise shared) link to a **GitHub repo** that contains:
    1. A 5-minute (OR LESS) loom video of a live **demo of your application** that also describes the use case.
    2. A **written document** addressing each deliverable and answering each question
    3. All relevant code